{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run\n",
    "\n",
    "> Execution module for Deep Animator library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import imageio\n",
    "\n",
    "from fastscript import call_parse, Param\n",
    "\n",
    "from deep_animator.utils import load_checkpoints, animate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@call_parse\n",
    "def deep_animate(source: Param('Path to the source image.', str, opt=False), \n",
    "                 driving: Param('Path to the driving video.', str, opt=False), \n",
    "                 config: Param('Path to configuration file', str, opt=False), \n",
    "                 checkpoint: Param('Path to model', str, opt=False), \n",
    "                 dest: Param('Path to save the generated video', str) = 'generated_video.mp4', \n",
    "                 relative: Param('Relative', bool) = True, \n",
    "                 adapt_movement_scale: Param('Adaptive moment scale', bool) = True):\n",
    "    \n",
    "    source_image = imageio.imread(source)\n",
    "    driving_video = imageio.mimread(driving)\n",
    "    \n",
    "    # resize image and video to 256x256\n",
    "    source_image = resize(source_image, (256, 256))[..., :3]\n",
    "    driving_video = [resize(frame, (256, 256))[..., :3] for frame in driving_video]\n",
    "    \n",
    "    generator, kp_detector = load_checkpoints(config_path=config, checkpoint_path=checkpoint)\n",
    "    \n",
    "    predictions = animate(source_image, driving_video, generator, kp_detector, relative=relative, \n",
    "                          adapt_movement_scale=adapt_movement_scale)\n",
    "    \n",
    "    imageio.mimsave(dest, [img_as_ubyte(frame) for frame in predictions])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep_animator]",
   "language": "python",
   "name": "conda-env-deep_animator-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
